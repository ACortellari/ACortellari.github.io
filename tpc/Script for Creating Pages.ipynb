{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "from datetime import date\n",
    "\n",
    "today = date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_page = \"[The Turkey-Palestine Source Collection](turkey_palestine_collection.md)\"\n",
    "separator = \" // \"\n",
    "\n",
    "page_heading_element = \"# \"\n",
    "page_heading_element_2 = \"## \"\n",
    "\n",
    "project_folder = 'Sol-idarities\\Sources Database'\n",
    "upper_category = 'firstlevel_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_view = pd.read_csv(rf'C:\\Users\\act1780\\Documents\\GitHub\\{project_folder}\\articles_view.csv', delimiter='\\t')\n",
    "publications_view = pd.read_csv(fr'C:\\Users\\act1780\\Documents\\GitHub\\{project_folder}\\publications_view.csv', delimiter='\\t')\n",
    "issues_table = pd.read_csv(fr'C:\\Users\\act1780\\Documents\\GitHub\\{project_folder}\\issues_view.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-usable Blocks\n",
    "Sets a few blocks that can be reused throughout the website as variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of available views from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = fr\"C:\\Users\\act1780\\Documents\\GitHub\\andreacortellari.github.io\\{project_folder}/*\" \n",
    "files_list = glob.glob(folder_path)\n",
    "\n",
    "list_of_files = []\n",
    "list_of_views = []\n",
    "for file_path in files_list:\n",
    "    if '.csv' in file_path:\n",
    "        view_name = file_path.split('.')[-2].split(\"\\\\\")[-1]\n",
    "        formatted_view_name = f\"* {view_name}\"\n",
    "        list_of_files.append(formatted_view_name)\n",
    "        list_of_views.append(view_name)\n",
    "\n",
    "files = str(list_of_files).replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create First Level Pages\n",
    "Uses a for loop to create a main page for **articles**, **issues**, and **publication** using some metadata and data from the database views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "publications_metadata = f\"In our dataset, we have {len(publications_view['publication_title'].unique())} unique publication names. The earliest publication started in {min(publications_view['first_year'].dropna())}, while the latest publication ended in {max(publications_view['last_year'].dropna())}. These publications are spread across various locations including {', '.join(sorted(publications_view['publication_location'].dropna().unique()))}.\"\n",
    "column_to_drop = ['article_id', 'article_text', 'author_type', 'publication_id']\n",
    "sorting_by_columns = ['issue_year', 'issue_month']\n",
    "\n",
    "for first_level_page in list_of_views:\n",
    "    filename = rf\"{upper_category}{first_level_page.split('_')[0]}.md\"\n",
    "    view_file = pd.read_csv(rf'C:\\Users\\act1780\\Documents\\GitHub\\andreacortellari.github.io\\{project_folder}\\{first_level_page}.csv', delimiter='\\t')\n",
    "    view_file = view_file\\\n",
    "        .sort_values(by=[col for col in sorting_by_columns if col in view_file.columns], \n",
    "                     ascending=[True for col in sorting_by_columns if col in view_file.columns])\\\n",
    "        .drop(columns=[col for col in column_to_drop if col in view_file.columns])\n",
    "\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"{page_heading_element}{home_page}{separator}{first_level_page.split('_')[-0].title()}\\n\\n\")\n",
    "        f. write(f\"{publications_metadata} The webpage showcases data sourced from the {first_level_page} of the database. Download this view as a .csv file <a href='https://github.com/andreacortellari/andreacortellari.github.io/blob/main/{project_folder}\\{first_level_page}.csv'>by clicking on the link.</a>\\n\\n\")\n",
    "        f.write((view_file).to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create each Publications' Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\act1780\\\\Documents\\\\GitHub\\\\andrea.cortellari.github.io\\\\Sol-idarities\\\\Sources Database\\\\publications_view.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m columns_publications_articles \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marticle_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marticle_text\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor_type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpages\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublication_title\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregular_feature_title\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mact1780\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGitHub\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mandrea.cortellari.github.io\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproject_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpublications_view.csv\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Change this to the path of your CSV file\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(csv_file, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n\u001b[0;32m      6\u001b[0m         reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mDictReader(csvfile, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28mprint\u001b[39m(reader)\n",
      "File \u001b[1;32mc:\\Users\\act1780\\AppData\\Local\\anaconda3\\envs\\MyPetProject\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\act1780\\\\Documents\\\\GitHub\\\\andrea.cortellari.github.io\\\\Sol-idarities\\\\Sources Database\\\\publications_view.csv'"
     ]
    }
   ],
   "source": [
    "columns_publications_articles = ['article_id', 'article_text', 'author_type', 'pages', 'publication_title', 'regular_feature_title']\n",
    "\n",
    "csv_file = fr'C:\\Users\\act1780\\Documents\\GitHub\\andrea.cortellari.github.io\\{project_folder}\\publications_view.csv'  # Change this to the path of your CSV file\n",
    "    \n",
    "with open(csv_file, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile, delimiter='\\t')\n",
    "        print(reader)\n",
    "        for row in reader:\n",
    "            publication_name = row['publication_title']\n",
    "            publication_type = row['publication_type']\n",
    "            start_year = row['first_year']\n",
    "            end_year = row['last_year']\n",
    "            total_issues = row['total_issues']\n",
    "            publication_location = row['publication_location']\n",
    "            articles = articles_view[articles_view['publication_title'] == publication_name]\n",
    "\n",
    "            metadata = f\"{publication_name} was a {publication_type} publication. It published {total_issues} issues in {publication_location} between {start_year} and {end_year}.\"\n",
    "            \n",
    "            filename = rf\"C:\\Users\\act1780\\Documents\\GitHub\\andreacortellari.github.io\\_posts\\2024-04-01-{publication_name}.md\"\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(f\"\"\"---\n",
    "title: {publication_name}\n",
    "date: 2024-04-18 21:15:00 +0100\n",
    "categories: [Publications]\n",
    "tags: []\n",
    "---\\n\\n\"\"\")\n",
    "                f.write(f\"{metadata}\\n\\n\")\n",
    "                f.write(f\"{publications_metadata}\\n\\n\")\n",
    "                f.write(f\"{page_heading_element_2}Articles in Scope\\n\\n\")\n",
    "                f.write(f\"{articles.drop(columns=columns_publications_articles).to_markdown(index=False)}\\n\\n\" if len(articles) >= 1 else \"No article focused on Palestine in our database.\\n\\n\")\n",
    "                f.write(f\"{page_heading_element_2}Issues Summary\\n\\n\")\n",
    "                f.write(issues_table[issues_table['publication_title'] == publication_name].drop(columns=['publication_id', 'publication_title', 'printing_house_name']).to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create each articles' page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_with_text = articles_view[articles_view['article_text'].notna()]\n",
    "\n",
    "for index, row in articles_with_text.iterrows():\n",
    "    filename = rf\"articles_{row['article_title'].replace('?', '')}.md\"\n",
    "    metadata_table = articles_with_text.loc[articles_with_text['article_title'] == row['article_title']].drop(columns={'article_text'})\n",
    "\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"{page_heading_element}{row['article_title']}\\n\\n\")\n",
    "        f.write(f\"{metadata_table.to_markdown(index=False)}\\n\\n\")\n",
    "        #f.write(f\"**Author:** {row['author']}\\n\\n\")\n",
    "        #f.write(f\"**Published on:** [{row['publication_title']}]({row['publication_title']}.md)\\n\\n\")\n",
    "        #f.write(f\"**Issue:** {row['issue_number']}, {row['issue_date']}\\n\\n\")\n",
    "        #f.write(f\"**Pages:** {row['pages']}\\n\\n\")\n",
    "        f.write(f\"{row['article_text']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(1968, 1972)\n",
    "months = range(1, 13)\n",
    "timeframe_in_range = []\n",
    "\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        year_month = f\"{year}-{month:02d}\"\n",
    "        timeframe_in_range.append(year_month)\n",
    "\n",
    "timeframe_in_range = pd.DataFrame(timeframe_in_range, columns=['issue_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(articles_view[['publication_title', 'issue_date', 'article_id']], timeframe_in_range, how='outer')\\\n",
    "    .pivot_table(index='issue_date', columns='publication_title', values='article_id', aggfunc='count', fill_value=0, dropna=False).reset_index()\\\n",
    "    .to_csv('data_jobs\\Articles Distribution.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyPetProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
