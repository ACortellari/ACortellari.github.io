{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "from datetime import date\n",
    "\n",
    "today = date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_page = \"[The Turkey-Palestine Source Collection](turkey_palestine_collection.md)\"\n",
    "separator = \" // \"\n",
    "\n",
    "page_heading_element = \"# \"\n",
    "page_heading_element_2 = \"## \"\n",
    "\n",
    "project_folder = 'tpc\\Sources Database'\n",
    "upper_category = 'firstlevel_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_view = pd.read_csv(rf'C:\\Users\\act1780\\Documents\\GitHub\\andreacortellari.github.io\\{project_folder}\\articles_view.csv', delimiter='\\t')\n",
    "publications_view = pd.read_csv(fr'C:\\Users\\act1780\\Documents\\GitHub\\andreacortellari.github.io\\{project_folder}\\publications_view.csv', delimiter='\\t')\n",
    "issues_table = pd.read_csv(fr'C:\\Users\\act1780\\Documents\\GitHub\\andreacortellari.github.io\\{project_folder}\\issues_view.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-usable Blocks\n",
    "Sets a few blocks that can be reused throughout the website as variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Last Update box with the date of today (day of run).\n",
    "\n",
    "last_update = f\"\"\"\n",
    "```\n",
    "Last Update: {today}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of available views from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'* articles * articles_view * issues_view * publications_view'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = fr\"C:\\Users\\act1780\\Documents\\GitHub\\andreacortellari.github.io\\{project_folder}/*\" \n",
    "files_list = glob.glob(folder_path)\n",
    "\n",
    "list_of_files = []\n",
    "list_of_views = []\n",
    "for file_path in files_list:\n",
    "    view_name = file_path.split('.')[-2].split(\"\\\\\")[-1]\n",
    "    formatted_view_name = f\"* {view_name}\"\n",
    "    list_of_files.append(formatted_view_name)\n",
    "    list_of_views.append(view_name)\n",
    "\n",
    "files = str(list_of_files).replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create First Level Pages\n",
    "Uses a for loop to create a main page for **articles**, **issues**, and **publication** using some metadata and data from the database views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = f\"In our dataset, we have {len(publications_view['publication_title'].unique())} unique publication names. The earliest publication started in {min(publications_view['first_year'])}, while the latest publication ended in {max(publications_view['last_year'])}. These publications are spread across various locations including {', '.join(sorted(publications_view['publication_location'].unique()))}.\"\n",
    "column_to_drop = ['article_id', 'article_text', 'author_type']\n",
    "sorting_by_columns = ['issue_year', 'issue_month']\n",
    "\n",
    "for first_level_page in list_of_views:\n",
    "    filename = rf\"{upper_category}{first_level_page.split('_')[0]}.md\"\n",
    "    view_file = pd.read_csv(rf'C:\\Users\\act1780\\Documents\\GitHub\\andreacortellari.github.io\\{project_folder}\\{first_level_page}.csv', delimiter='\\t')\n",
    "    view_file = view_file\\\n",
    "        .sort_values(by=[col for col in sorting_by_columns if col in view_file.columns], \n",
    "                     ascending=[True for col in sorting_by_columns if col in view_file.columns])\\\n",
    "        .drop(columns=[col for col in column_to_drop if col in view_file.columns])\n",
    "\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"{page_heading_element}{home_page}{separator}{first_level_page.split('_')[-0].title()}\\n\\n\")\n",
    "        f. write(f\"{metadata} The webpage showcases data sourced from the {first_level_page} of the database. Download this view as a .csv file <a href='https://github.com/andreacortellari/andreacortellari.github.io/blob/main/{project_folder}\\{first_level_page}.csv'>by clicking on the link.</a>\\n\\n\")\n",
    "        f.write((view_file).to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create each Publications' Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_publications_articles = ['article_id', 'article_text', 'publication_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<csv.DictReader object at 0x0000021AF2B93F10>\n"
     ]
    }
   ],
   "source": [
    "csv_file = fr'C:\\Users\\act1780\\Documents\\GitHub\\andreacortellari.github.io\\{project_folder}\\publications_view.csv'  # Change this to the path of your CSV file\n",
    "    \n",
    "with open(csv_file, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile, delimiter='\\t')\n",
    "        print(reader)\n",
    "        for row in reader:\n",
    "            publication_name = row['publication_title']\n",
    "            publication_type = row['publication_type']\n",
    "            start_year = row['first_year']\n",
    "            end_year = row['last_year']\n",
    "            total_issues = row['total_issues']\n",
    "            publication_location = row['publication_location']\n",
    "\n",
    "            metadata = f\"{publication_name} was a {publication_type} publication. It published {total_issues} issues in {publication_location} between {start_year} and {end_year}.\"\n",
    "            \n",
    "            filename = rf\"publications_{publication_name.replace(' ', '_')}.md\"\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(f\"{page_heading_element}[Publications]({upper_category}publications.md){separator}{publication_name}\\n\\n\")\n",
    "                f.write(f\"{metadata}\\n\\n\")\n",
    "                f.write(f\"{page_heading_element_2}Articles in Scope\\n\\n\")\n",
    "                f.write(f\"{articles_view[articles_view['publication_title'] == publication_name].drop(columns=columns_publications_articles).to_markdown(index=False)}\\n\\n\")\n",
    "                f.write(f\"{page_heading_element_2}Issues Summary\\n\\n\")\n",
    "                f.write(issues_table[issues_table['publication_title'] == publication_name].sort_values(by=['issue_year', 'issue_month']).to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create each articles' page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_with_text = articles_view[articles_view['article_text'].notna()]\n",
    "\n",
    "for index, row in articles_with_text.iterrows():\n",
    "    filename = rf\"articles_{row['article_title'].replace('?', '')}.md\"\n",
    "    metadata_table = articles_with_text.loc[articles_with_text['article_title'] == row['article_title']].drop(columns={'article_text'})\n",
    "\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"{page_heading_element}{row['article_title']}\\n\\n\")\n",
    "        f.write(f\"{metadata_table.to_markdown(index=False)}\\n\\n\")\n",
    "        #f.write(f\"**Author:** {row['author']}\\n\\n\")\n",
    "        #f.write(f\"**Published on:** [{row['publication_title']}]({row['publication_title']}.md)\\n\\n\")\n",
    "        #f.write(f\"**Issue:** {row['issue_number']}, {row['issue_date']}\\n\\n\")\n",
    "        #f.write(f\"**Pages:** {row['pages']}\\n\\n\")\n",
    "        f.write(f\"{row['article_text']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Collection main page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a main menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ARTICLES](firstlevel_articles.md) // [ISSUES](firstlevel_issues.md) // [PUBLICATIONS](firstlevel_publications.md)'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = r\"C:\\Users\\act1780\\Documents\\GitHub\\andreacortellari.github.io\\tpc/first*.md\"  # Replace this with the path to your folder\n",
    "first_level_list = glob.glob(folder_path)\n",
    "\n",
    "menu = f'{separator}'.join([f\"[{levels.split(os.path.sep)[-1].split('_')[-1].split('.')[-2].upper()}]({levels.split(os.path.sep)[-1]})\" for levels in first_level_list])\n",
    "menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = rf\"turkey_palestine_collection.md\"\n",
    "with open(filename, 'w', encoding='utf-8') as f:\n",
    "    f.write(f\"{page_heading_element}{home_page}\\n\\n\")\n",
    "    f.write(f\"{page_heading_element}{menu}\")\n",
    "    f.write(f\"{last_update}\\n\\n\")\n",
    "    f.write(f\"This page is a humble list of sources, primarily collected from mainstream and leftist press, that can be useful to those interested in studying the history of the radical left in Turkey, specifically its linkages and intellectual connections with Palestinian organizations from the late 1960s to the early 1970s.\\n\\n\") \n",
    "    f.write(f\"The bulk of the corpus listed—and sometimes provided in textual form—here is the result of research efforts that occupied me in 2018-19 while working on the Master's Thesis as part of my MA in Middle Eastern Studies at Leiden University. I completed my thesis, titled <a href='https://studenttheses.universiteitleiden.nl/handle/1887/82728'>Bringing Palestine Home: A Transnational History of Turkey's Radical Left and Palestine (1967-1972)</a>, under the supervision of Dr. Alp A. Yenen.\\n\\n\") \n",
    "    f.write(f\"The rich corpus of primary sources accessible through the digitization efforts of Türkiye Sosyal Tarih Araştırma Vakfı (TÜSTAV) significantly facilitated my research. I am grateful for TÜSTAV's valuable contributions to my endeavor. If any user believes that a valuable source is missing from this list (and that is most likely the case), I welcome and encourage suggestions. Your input is invaluable in enhancing the comprehensiveness of this small collection.\\n\\n\")\n",
    "    f.write(f\"{page_heading_element_2}Sources in the Leftist Press\\n\\n\")\n",
    "    f.write(f\"The sources provided here span the years 1968 to 1971 representing just a fraction of the leftist weekly and monthly publications from that period. Although the initial corpus was more extensive, only the sources included in my bibliography are currently listed. Additional sources may gradually be made available in the <a href='https://github.com/andreacortellari/andreacortellari.github.io/tree/main/tpc/Sources%20Database'>Sources Database</a> (as .csv files for ease in fruition). \\n\\n\") \n",
    "    f.write(f\"The database includes the following:\\n\\n\")\n",
    "    f.write('\\n'.join([file_path for file_path in list_of_files]))\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(f\"{page_heading_element_2}Ongoing Work:\\n\\n\")\n",
    "    f.write(f\"* Add additional publications from the period in scope to the **{len(publications_view['publication_title'].unique())}** unique publications already in the database.\\n\")\n",
    "    f.write(f\"* Add additional sources to the **{len(articles_view['article_title'].unique())}** articles already in the database.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyPetProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
