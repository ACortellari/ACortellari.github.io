{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "from datetime import date\n",
    "\n",
    "today = date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_page = \"[The Turkey-Palestine Source Collection](turkey_palestine_collection.md)\"\n",
    "separator = \" // \"\n",
    "\n",
    "page_heading_element = \"# \"\n",
    "page_heading_element_2 = \"## \"\n",
    "\n",
    "project_folder = 'tpc\\Sources Database'\n",
    "upper_category = 'firstlevel_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_view = pd.read_csv(rf'C:\\Users\\act1780\\Documents\\GitHub\\andrea.cortellari.github.io\\{project_folder}\\articles_view.csv', delimiter='\\t')\n",
    "publications_view = pd.read_csv(fr'C:\\Users\\act1780\\Documents\\GitHub\\andrea.cortellari.github.io\\{project_folder}\\publications_view.csv', delimiter='\\t')\n",
    "issues_table = pd.read_csv(fr'C:\\Users\\act1780\\Documents\\GitHub\\andrea.cortellari.github.io\\{project_folder}\\issues_view.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-usable Blocks\n",
    "Sets a few blocks that can be reused throughout the website as variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of available views from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = fr\"C:\\Users\\act1780\\Documents\\GitHub\\andreacortellari.github.io\\{project_folder}/*\" \n",
    "files_list = glob.glob(folder_path)\n",
    "\n",
    "list_of_files = []\n",
    "list_of_views = []\n",
    "for file_path in files_list:\n",
    "    if '.csv' in file_path:\n",
    "        view_name = file_path.split('.')[-2].split(\"\\\\\")[-1]\n",
    "        formatted_view_name = f\"* {view_name}\"\n",
    "        list_of_files.append(formatted_view_name)\n",
    "        list_of_views.append(view_name)\n",
    "\n",
    "files = str(list_of_files).replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create First Level Pages\n",
    "Uses a for loop to create a main page for **articles**, **issues**, and **publication** using some metadata and data from the database views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "publications_metadata = f\"In our dataset, we have {len(publications_view['publication_title'].unique())} unique publication names. The earliest publication started in {min(publications_view['first_year'].dropna())}, while the latest publication ended in {max(publications_view['last_year'].dropna())}. These publications are spread across various locations including {', '.join(sorted(publications_view['publication_location'].dropna().unique()))}.\"\n",
    "column_to_drop = ['article_id', 'article_text', 'author_type', 'publication_id']\n",
    "sorting_by_columns = ['issue_year', 'issue_month']\n",
    "\n",
    "for first_level_page in list_of_views:\n",
    "    filename = rf\"{upper_category}{first_level_page.split('_')[0]}.md\"\n",
    "    view_file = pd.read_csv(rf'C:\\Users\\act1780\\Documents\\GitHub\\andreacortellari.github.io\\{project_folder}\\{first_level_page}.csv', delimiter='\\t')\n",
    "    view_file = view_file\\\n",
    "        .sort_values(by=[col for col in sorting_by_columns if col in view_file.columns], \n",
    "                     ascending=[True for col in sorting_by_columns if col in view_file.columns])\\\n",
    "        .drop(columns=[col for col in column_to_drop if col in view_file.columns])\n",
    "\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"{page_heading_element}{home_page}{separator}{first_level_page.split('_')[-0].title()}\\n\\n\")\n",
    "        f. write(f\"{publications_metadata} The webpage showcases data sourced from the {first_level_page} of the database. Download this view as a .csv file <a href='https://github.com/andreacortellari/andreacortellari.github.io/blob/main/{project_folder}\\{first_level_page}.csv'>by clicking on the link.</a>\\n\\n\")\n",
    "        f.write((view_file).to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create each Publications' Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<csv.DictReader object at 0x000001E76D5EF490>\n"
     ]
    }
   ],
   "source": [
    "columns_publications_articles = ['article_id', 'article_text', 'author_type', 'pages', 'publication_title', 'regular_feature_title']\n",
    "\n",
    "csv_file = fr'C:\\Users\\act1780\\Documents\\GitHub\\andrea.cortellari.github.io\\{project_folder}\\publications_view.csv'  # Change this to the path of your CSV file\n",
    "    \n",
    "with open(csv_file, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile, delimiter='\\t')\n",
    "        print(reader)\n",
    "        for row in reader:\n",
    "            publication_name = row['publication_title']\n",
    "            publication_type = row['publication_type']\n",
    "            start_year = row['first_year']\n",
    "            end_year = row['last_year']\n",
    "            total_issues = row['total_issues']\n",
    "            publication_location = row['publication_location']\n",
    "            articles = articles_view[articles_view['publication_title'] == publication_name]\n",
    "\n",
    "            metadata = f\"{publication_name} was a {publication_type} publication. It published {total_issues} issues in {publication_location} between {start_year} and {end_year}.\"\n",
    "            \n",
    "            filename = rf\"C:\\Users\\act1780\\Documents\\GitHub\\andreacortellari.github.io\\_posts\\2024-04-01-{publication_name}.md\"\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(f\"\"\"---\n",
    "title: {publication_name}\n",
    "date: 2024-04-18 21:15:00 +0100\n",
    "categories: [Publications]\n",
    "tags: []\n",
    "---\\n\\n\"\"\")\n",
    "                f.write(f\"{metadata}\\n\\n\")\n",
    "                f.write(f\"{publications_metadata}\\n\\n\")\n",
    "                f.write(f\"{page_heading_element_2}Articles in Scope\\n\\n\")\n",
    "                f.write(f\"{articles.drop(columns=columns_publications_articles).to_markdown(index=False)}\\n\\n\" if len(articles) >= 1 else \"No article focused on Palestine in our database.\\n\\n\")\n",
    "                f.write(f\"{page_heading_element_2}Issues Summary\\n\\n\")\n",
    "                f.write(issues_table[issues_table['publication_title'] == publication_name].drop(columns=['publication_id', 'publication_title', 'printing_house_name']).to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create each articles' page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_with_text = articles_view[articles_view['article_text'].notna()]\n",
    "\n",
    "for index, row in articles_with_text.iterrows():\n",
    "    filename = rf\"articles_{row['article_title'].replace('?', '')}.md\"\n",
    "    metadata_table = articles_with_text.loc[articles_with_text['article_title'] == row['article_title']].drop(columns={'article_text'})\n",
    "\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"{page_heading_element}{row['article_title']}\\n\\n\")\n",
    "        f.write(f\"{metadata_table.to_markdown(index=False)}\\n\\n\")\n",
    "        #f.write(f\"**Author:** {row['author']}\\n\\n\")\n",
    "        #f.write(f\"**Published on:** [{row['publication_title']}]({row['publication_title']}.md)\\n\\n\")\n",
    "        #f.write(f\"**Issue:** {row['issue_number']}, {row['issue_date']}\\n\\n\")\n",
    "        #f.write(f\"**Pages:** {row['pages']}\\n\\n\")\n",
    "        f.write(f\"{row['article_text']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(1968, 1972)\n",
    "months = range(1, 13)\n",
    "timeframe_in_range = []\n",
    "\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        year_month = f\"{year}-{month:02d}\"\n",
    "        timeframe_in_range.append(year_month)\n",
    "\n",
    "timeframe_in_range = pd.DataFrame(timeframe_in_range, columns=['issue_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(articles_view[['publication_title', 'issue_date', 'article_id']], timeframe_in_range, how='outer')\\\n",
    "    .pivot_table(index='issue_date', columns='publication_title', values='article_id', aggfunc='count', fill_value=0, dropna=False).reset_index()\\\n",
    "    .to_csv('data_jobs\\Articles Distribution.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyPetProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
